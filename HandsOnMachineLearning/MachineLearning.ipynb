{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 1. 한눈에 보는 머신러닝\n",
    "\n",
    "### 머신러닝의 절차\n",
    "1. 데이터를 분석\n",
    "2. 모델을 선택\n",
    "3. 데이터의 전처리  \n",
    "    a) 특성 선택 / 특성 추출   \n",
    "    b) 일반화  \n",
    "    c) 정규화(각 차원별로 균질) \n",
    "4. 훈련 데이터로 모델을 훈련  \n",
    "    a) 학습 알고리즘이 비용함수를 최소화하는 모델 파라미터를 파악\n",
    "5. 검증 데이터로 모델을 검증\n",
    "6. 테스트 데이터로 모델을 테스트\n",
    "\n",
    "### 머신러닝의 종류\n",
    "1. 지도, 비지도, 준지도, 강화\n",
    "2. 온라인, 배치\n",
    "3. 사례기반, 모델기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 2. 머신러닝 프로젝트 처음부터 끝까지\n",
    "\n",
    "### 머신러닝의 큰 그림\n",
    "1. 문제정의\n",
    "2. 성능 측정 지표 선택\n",
    "3. 가정 검사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap 3. 분류\n",
    "\n",
    "### 성능 측정 지표\n",
    "1. 정확도를 성능 측정 지표로 선호하지 않음.  \n",
    "    a) 불균형한 데이터셋(어떤 클래스가 월등히 많은 경우)일 경우 더욱 그러함.\n",
    "2. 오차행렬을 이용하여 성능을 측정  \n",
    "    a) TP: True / Positive  \n",
    "    b) TN: True / Negative  \n",
    "    c) FP: False / Positive  \n",
    "    d) FN: False / Negative  \n",
    "3. 오차행렬을 이용하여 성능측정 지표 도출  \n",
    "    a) $Precision = \\frac{TP}{TP+FP}$, $FP$와 반비례    \n",
    "    b) $Recall = \\frac{TP}{TP+FN}$, $FN$와 반비례  \n",
    "    c) $False$를 $Positive$로 예측할 것이냐, $Negative$로 예측할 것인가는 서로 트레이드오프 관계  \n",
    "    d) 즉, precision과 recall은 트레이드오프 관계    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chap 4. 모델훈련\n",
    "\n",
    "1. 선형회귀    \n",
    "a) 모델: 선형모델\n",
    "$$\\hat{y} = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{1}x_{1}+\\cdots+\\theta_{n}x_{n}$$\n",
    "b) 비용함수: MSE(Mean Squared Error)\n",
    "$$MSE(X,h_{\\theta})=\\frac{1}{m}\\sum _{ i=1}^{m}{(\\theta^{T}\\cdot x^{(i)} - y^{i})^{2}} $$\n",
    "c) 최적화: 정규방정식, 배치 경사하강법, 확률적 경사하강법, 미니배치 경사하강법  \n",
    "\n",
    "2. 모델의 오차  \n",
    ": 모델의 일반화 오차는 세가지의 다른 종류의 오차의 합으로 표현  \n",
    "a) 편향(bias)  \n",
    "b) 분산(variance)  \n",
    "c) 줄일 수 없는 오차(irreducibe error)  \n",
    "\n",
    "3. 편향/분산 트레이드오프\n",
    "\n",
    "4. 규제가 있는 선형모델  \n",
    ": 규제항이 비용함수에 추가.  \n",
    "a) 릿지회귀  \n",
    "b) 라쏘회귀  \n",
    "c) 엘라스틱넷  \n",
    "\n",
    "5. 조기종료(Early stopping)  \n",
    ": 제프리 힌튼이 언급한 훌륭한 공짜 점심(beautiful free launch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chap 5. 서포트 벡터 머신\n",
    "\n",
    "1. SVM(서포트 벡터 머신)의 특징  \n",
    "a) 복잡한 분류문제와 작거나, 중간의 데이터 셋에 적합  \n",
    "b) 특성의 스케일에 민감  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
